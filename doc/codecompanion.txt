*codecompanion.txt*         For NVIM v0.9.2         Last change: 2024 April 03

==============================================================================
Table of Contents                            *codecompanion-table-of-contents*

  - Features                                          |codecompanion-features|
  - Requirements                                  |codecompanion-requirements|
  - Installation                                  |codecompanion-installation|
  - Configuration                                |codecompanion-configuration|
  - Usage                                                |codecompanion-usage|
  - Helpers                                            |codecompanion-helpers|

FEATURES                                              *codecompanion-features*

- A Copilot Chat experience from within Neovim
- Adapter support for many generative AI services
- Agentic workflows to improve LLM output
- Inline code creation and modification
- Built in actions for specific language prompts, LSP error fixes and code advice
- Create your own custom actions for Neovim
- Save and restore your chats
- Async execution for improved performance


REQUIREMENTS                                      *codecompanion-requirements*

- The `curl` library installed
- Neovim 0.9.2 or greater
- _(Optional)_ An API key for your chosen generative AI service


INSTALLATION                                      *codecompanion-installation*

Install the plugin with your package manager of choice:

>lua
    -- Lazy.nvim
    {
      "olimorris/codecompanion.nvim",
      dependencies = {
        "nvim-lua/plenary.nvim",
        "nvim-treesitter/nvim-treesitter",
        "nvim-telescope/telescope.nvim", -- Optional
        {
          "stevearc/dressing.nvim", -- Optional: Improves the default Neovim UI
          opts = {},
        },
      },
      config = true
    }
    
    -- Packer.nvim
    use({
      "olimorris/codecompanion.nvim",
      config = function()
        require("codecompanion").setup()
      end,
      requires = {
        "nvim-lua/plenary.nvim",
        "nvim-treesitter/nvim-treesitter",
        "nvim-telescope/telescope.nvim", -- Optional
        "stevearc/dressing.nvim" -- Optional: Improves the default Neovim UI
      }
    })
<


CONFIGURATION                                    *codecompanion-configuration*

You only need to the call the `setup` function if you wish to change any of the
defaults:

Click to see the default configuration ~

>lua
    require("codecompanion").setup({
      adapters = {
        anthropic = require("codecompanion.adapters").use("anthropic"),
        ollama = require("codecompanion.adapters").use("ollama"),
        openai = require("codecompanion.adapters").use("openai"),
      },
      strategies = {
        chat = "openai",
        inline = "openai",
      },
      saved_chats = {
        save_dir = vim.fn.stdpath("data") .. "/codecompanion/saved_chats", -- Path to save chats to
      },
      display = {
        action_palette = {
          width = 95,
          height = 10,
        },
        chat = { -- Options for the chat strategy
          type = "float", -- float|buffer
          show_settings = true, -- Show the model settings in the chat buffer?
          show_token_count = true, -- Show the token count for the current chat in the buffer?
          buf_options = { -- Buffer options for the chat buffer
            buflisted = false,
          },
          float_options = { -- Float window options if the type is "float"
            border = "single",
            buflisted = false,
            max_height = 0,
            max_width = 0,
            padding = 1,
          },
          win_options = { -- Window options for the chat buffer
            cursorcolumn = false,
            cursorline = false,
            foldcolumn = "0",
            linebreak = true,
            list = false,
            signcolumn = "no",
            spell = false,
            wrap = true,
          },
        },
      },
      keymaps = {
        ["<C-s>"] = "keymaps.save", -- Save the chat buffer and trigger the API
        ["<C-c>"] = "keymaps.close", -- Close the chat buffer
        ["q"] = "keymaps.cancel_request", -- Cancel the currently streaming request
        ["gc"] = "keymaps.clear", -- Clear the contents of the chat
        ["ga"] = "keymaps.codeblock", -- Insert a codeblock into the chat
        ["gs"] = "keymaps.save_chat", -- Save the current chat
        ["]"] = "keymaps.next", -- Move to the next header in the chat
        ["["] = "keymaps.previous", -- Move to the previous header in the chat
      },
      log_level = "ERROR", -- TRACE|DEBUG|ERROR
      send_code = true, -- Send code context to the generative AI service? Disable to prevent leaking code outside of Neovim
      silence_notifications = false, -- Silence notifications for actions like saving saving chats?
      use_default_actions = true, -- Use the default actions in the action palette?
    })
<


ADAPTERS ~


  [!WARNING] Depending on your chosen adapter
  <https://github.com/olimorris/codecompanion.nvim/tree/main/lua/codecompanion/adapters>,
  you may need to set an API key.
The plugin uses adapters to bridge between generative AI services and the
plugin (notably strategies). Currently the plugin supports:

- Anthropic (`anthropic`) - Requires an API key
- Ollama (`ollama`)
- OpenAI (`openai`) - Requires an API key

Strategies are the different ways that a user can interact with the plugin. The
_chat_ strategy harnesses a buffer to allow direct conversation with the
generative AI service. The _inline_ strategy allows for output from the
generative AI service to be written directly into a pre-existing Neovim buffer.

To specify a different adapter to the defaults, you can map an adapter to a
strategy:

>lua
    require("codecompanion").setup({
      strategies = {
        chat = "ollama",
        inline = "ollama"
      },
    })
<

You can customise an adapter’s configuration as follows:

>lua
    require("codecompanion").setup({
      adapters = {
        anthropic = require("codecompanion.adapters").use("anthropic", {
          env = {
            api_key = "ANTHROPIC_API_KEY_1"
          },
        }),
      },
    })
<

In the example above, we’ve changed the name of the default API key which the
Anthropic adapter uses. Having API keys in plain text in your shell is not
always safe. Thanks to this PR
<https://github.com/olimorris/codecompanion.nvim/pull/24>, you can run commands
from within the configuration:

>lua
    require("codecompanion").setup({
      adapters = {
        chat = require("codecompanion.adapters").use("openai", {
          env = {
            api_key = "cmd:gpg --decrypt ~/.openai-api-key.gpg 2>/dev/null",
          },
        }),
      },
    })
<

In this example, we’re using `gpg` to decrypt a file to obtain an API key for
OpenAI.


  [!TIP] To create your own adapter please refer to the ADAPTERS <ADAPTERS.md>
  guide.

EDGY.NVIM CONFIGURATION ~

The author recommends pairing with edgy.nvim
<https://github.com/folke/edgy.nvim> for an experience similar to that of
GitHub’s Copilot Chat:

>lua
    {
      "folke/edgy.nvim",
      event = "VeryLazy",
      init = function()
        vim.opt.laststatus = 3
        vim.opt.splitkeep = "screen"
      end,
      opts = {
        right = {
          { ft = "codecompanion", title = "Code Companion Chat", size = { width = 0.45 } },
        }
      }
    }
<


HIGHLIGHT GROUPS ~

The plugin sets the following highlight groups during setup:

- `CodeCompanionTokens` - Virtual text showing the token count when in a chat buffer
- `CodeCompanionVirtualText` - All other virtual text in the chat buffer


USAGE                                                    *codecompanion-usage*

The plugin has a number of commands:

- `:CodeCompanion` - Inline code writing and refactoring
- `:CodeCompanionChat` - To open up a new chat buffer
- `:CodeCompanionChat <adapter>` - To open up a new chat buffer with a specific adapter
- `:CodeCompanionToggle` - Toggle a chat buffer
- `:CodeCompanionActions` - To open up the action palette window

For an optimum workflow, the plugin author recommendeds the following:

>lua
    vim.api.nvim_set_keymap("n", "<C-a>", "<cmd>CodeCompanionActions<cr>", { noremap = true, silent = true })
    vim.api.nvim_set_keymap("v", "<C-a>", "<cmd>CodeCompanionActions<cr>", { noremap = true, silent = true })
    vim.api.nvim_set_keymap("n", "<LocalLeader>a", "<cmd>CodeCompanionToggle<cr>", { noremap = true, silent = true })
    vim.api.nvim_set_keymap("v", "<LocalLeader>a", "<cmd>CodeCompanionToggle<cr>", { noremap = true, silent = true })
    
    -- Expand `cc` into CodeCompanion in the command line
    vim.cmd([[cab cc CodeCompanion]])
<


  [!NOTE] For some actions, visual mode allows your selection to be sent directly
  to the chat buffer or the API itself (in the case of _inline code_ actions).

THE ACTION PALETTE ~


  [!NOTE] Please see the RECIPES <RECIPES.md> guide in order to add your own
  actions to the palette.
The Action Palette, opened via `:CodeCompanionActions`, contains all of the
actions and their associated strategies for the plugin. It’s the fastest way
to start leveraging CodeCompanion. Depending on whether you’re in _normal_ or
_visual_ mode will affect the options that are available to you in the palette.


  [!TIP] If you wish to turn off the default actions, set `use_default_actions =
  false` in your config.

THE CHAT BUFFER ~

The chat buffer is where you can converse with the generative AI service,
directly from Neovim. It behaves as a regular markdown buffer with some clever
additions. When the buffer is written (or "saved"), autocmds trigger the
sending of its content to the generative AI service in the form of prompts.
These prompts are segmented by H1 headers: `user`, `system` and `assistant`.
When a response is received, it is then streamed back into the buffer. The
result is that you experience the feel of conversing with your generative AI
service from within Neovim.


KEYMAPS

When in the chat buffer, there are number of keymaps available to you:

- `<C-s>` - Save the buffer and trigger a response from the generative AI service
- `<C-c>` - Close the buffer
- `q` - Cancel the stream from the API
- `gc` - Clear the buffer’s contents
- `ga` - Add a codeblock
- `gs` - Save the chat to disk
- `[` - Move to the next header
- `]` - Move to the previous header


SAVED CHATS

Chat buffers are not saved to disk by default, but can be by pressing `gs` in
the buffer. Saved chats can then be restored via the Action Palette and the
_Load saved chats_ action.


SETTINGS

If `display.chat.show_settings` is set to `true`, at the very top of the chat
buffer will be the adapter’s model parameters which can be changed to tweak
the response. You can find more detail about them by moving the cursor over
them.


INLINE CODE ~


https://github.com/olimorris/codecompanion.nvim/assets/9512444/0a448d12-5b8b-4932-b2e9-871eec45c534

You can use the plugin to create inline code directly into a Neovim buffer.
This can be invoked by using the _Action Palette_ (as above) or from the
command line via `:CodeCompanion`. For example:

>
    :CodeCompanion create a table of 5 fruits
<

>
    :'<,'>CodeCompanion refactor the code to make it more concise
<


  [!NOTE] The command can detect if you’ve made a visual selection and send any
  code as context to the API alongside the filetype of the buffer.
One of the challenges with inline editing is determining how the generative
AI’s response should be handled in the buffer. If you’ve prompted the API
to _“create a table of 5 fruits”_ then you may wish for the response to be
placed after the cursor’s current position in the buffer. However, if you
asked the API to _“refactor this function”_ then you’d expect the
response to overwrite a visual selection. If this placement isn’t specified
then the plugin will use generative AI itself to determine if the response
should follow any of the placements below:

- _after_ - after the visual selection
- _before_ - before the visual selection
- _cursor_ - one column after the cursor position
- _new_ - in a new buffer
- _replace_ - replacing the visual selection

As a final example, specifying a prompt like _“create a test for this code in
a new buffer”_ would result in a new Neovim buffer being created.


IN-BUILT ACTIONS ~

The plugin comes with a number of in-built actions
<https://github.com/olimorris/codecompanion.nvim/blob/main/lua/codecompanion/actions.lua>
which aim to improve your Neovim workflow. Actions make use of either a _chat_
or an _inline_ strategy. As mentioned above, the chat strategy opens up a chat
buffer whilst an inline strategy will write output from the generative AI
service into a Neovim buffer.


CHAT AND CHAT AS


  [!TIP] Both of these actions allow for visually selected code to be sent to the
  chat buffer as code blocks.
Both of these actions utilise the `chat` strategy. The `Chat` action opens up a
fresh chat buffer. The `Chat as` action allows for persona based context to be
set in the chat buffer allowing for better and more detailed responses from the
generative AI service.


OPEN CHATS

This action enables users to easily navigate between their open chat buffers. A
chat buffer can be deleted (and removed from memory) by pressing `<C-c>`.


AGENTIC WORKFLOWS


  [!WARNING] Agentic workflows may result in the significant consumption of
  tokens if you’re using an external generative AI service.
As outlined <https://www.deeplearning.ai/the-batch/issue-242/> by Andrew Ng,
agentic workflows have the ability to dramatically improve the output of an
LLM. Infact, it’s possible for older models like GPT 3.5 to outperform newer
models with traditional zero-shot inference. Andrew discussed
<https://www.youtube.com/watch?v=sal78ACtGTc&t=249s> how an agentic workflow
can be utilised via multiple prompts that invoke the LLM to self reflect.
Implementing Andrew’s advice, the plugin supports this notion via the use of
workflows. At various stages of a pre-defined workflow, the plugin will
automatically prompt the LLM without any input or triggering required from the
user.

Currently, the plugin only supports _“reflection”_ (multiple prompts within
the same application) and comes with the following workflows:

- Adding a new feature
- Refactoring code

Of course you can add new workflows by following the RECIPES <RECIPES.md>
guide.


INLINE CODE


  [!NOTE] The options available to the user in the Action Palette will depend on
  the Vim mode.
These actions utilize the `inline` strategy. They can be useful for writing
inline code in a buffer or even refactoring a visual selection; all based on a
user’s prompt. The actions are designed to write code for the buffer filetype
that it is initated in, or, if run from a terminal prompt, to write commands.

The strategy comes with a number of helpers which the user can type in the
prompt, similar to GitHub Copilot Chat
<https://github.blog/changelog/2024-01-30-code-faster-and-better-with-github-copilots-new-features-in-visual-studio/>

- `/doc`to add a documentation comment
- `/optimize` to analyze and improve the running time of the selected code
- `/tests` to create unit tests for the selected code


CODE ADVISOR


  [!NOTE] This option is only available in visual mode
As the name suggests, this action provides advice on a visual selection of code
and utilises the `chat` strategy. The response from the API is streamed into a
chat buffer which follows the `display.chat` settings in your configuration.


LSP ASSISTANT


  [!NOTE] This option is only available in visual mode
Taken from the fantastic Wtf.nvim <https://github.com/piersolenski/wtf.nvim>
plugin, this action provides advice on how to correct any LSP diagnostics which
are present on the visually selected lines. Again, the `send_code = false`
value can be set in your config to prevent the code itself being sent to the
generative AI service.


HELPERS                                                *codecompanion-helpers*


HOOKS / USER EVENTS ~

The plugin fires the following events during its lifecycle:

- `CodeCompanionRequest` - Fired during the API request. Outputs `data.status` with a value of `started` or `finished`
- `CodeCompanionChatSaved` - Fired after a chat has been saved to disk
- `CodeCompanionChat` - Fired at various points during the chat buffer. Comes with the following attributes:
    - `data.action = close_buffer` - For when a chat buffer has been permanently closed
    - `data.action = hide_buffer` - For when a chat buffer is hidden
    - `data.action = show_buffer` - For when a chat buffer is visible after being hidden
- `CodeCompanionInline` - Fired during the inline API request alongside `CodeCompanionRequest`. Outputs `data.status` with a value of `started` or `finished`

Events can be hooked into as follows:

>lua
    local group = vim.api.nvim_create_augroup("CodeCompanionHooks", {})
    
    vim.api.nvim_create_autocmd({ "User" }, {
      pattern = "CodeCompanionInline",
      group = group,
      callback = function(request)
        print(request.data.status) -- outputs "started" or "finished"
      end,
    })
<


  [!TIP] A possible use case is for formatting the buffer after an inline code
  request

STATUSLINES ~

It can be helpful to have a visual indicator in your statusline to know when
the plugin is communicating with a generative AI service. Below are two ways to
achieve this:


LUALINE.NVIM

>lua
    local M = require("lualine.component"):extend()
    
    M.processing = false
    M.spinner_index = 1
    
    local spinner_symbols = {
      "⠋",
      "⠙",
      "⠹",
      "⠸",
      "⠼",
      "⠴",
      "⠦",
      "⠧",
      "⠇",
      "⠏",
    }
    local spinner_symbols_len = 10
    
    -- Initializer
    function M:init(options)
      M.super.init(self, options)
    
      local group = vim.api.nvim_create_augroup("CodeCompanionHooks", {})
    
      vim.api.nvim_create_autocmd({ "User" }, {
        pattern = "CodeCompanionRequest",
        group = group,
        callback = function(request)
          self.processing = (request.data.status == "started")
        end,
      })
    end
    
    -- Function that runs every time statusline is updated
    function M:update_status()
      if self.processing then
        self.spinner_index = (self.spinner_index % spinner_symbols_len) + 1
        return spinner_symbols[self.spinner_index]
      else
        return nil
      end
    end
    
    return M
<


HEIRLINE.NVIM

>lua
    local CodeCompanion = {
      static = {
        processing = false,
      },
      update = {
        "User",
        pattern = "CodeCompanionRequest",
        callback = function(self, args)
          self.processing = (args.data.status == "started")
          vim.cmd("redrawstatus")
        end,
      },
      {
        condition = function(self)
          return self.processing
        end,
        provider = " ",
        hl = { fg = "yellow" },
      },
    }
<

Generated by panvimdoc <https://github.com/kdheepak/panvimdoc>

vim:tw=78:ts=8:noet:ft=help:norl:
