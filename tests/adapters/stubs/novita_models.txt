{
  {
    context_size = 64000,
    created = 1741174465,
    description = "DeepSeek R1 is the latest open-source model released by the DeepSeek team, featuring impressive reasoning capabilities, particularly achieving performance comparable to OpenAI's o1 model in mathematics, coding, and reasoning tasks.",
    display_name = "DeepSeek R1 (Turbo)\t",
    id = "deepseek/deepseek-r1-turbo",
    input_token_price_per_m = 7000,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 25000,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "deepseek/deepseek-r1-turbo"
  },
  {
    context_size = 64000,
    created = 1741174512,
    description = "DeepSeek-V3 is the latest model from the DeepSeek team, building upon the instruction following and coding abilities of the previous versions. Pre-trained on nearly 15 trillion tokens, the reported evaluations reveal that the model outperforms other open-source models and rivals leading closed-source models.",
    display_name = "DeepSeek V3 (Turbo)\t",
    id = "deepseek/deepseek-v3-turbo",
    input_token_price_per_m = 4000,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 13000,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "deepseek/deepseek-v3-turbo"
  },
  {
    context_size = 32768,
    created = 1741227869,
    description = "QwQ is the reasoning model of the Qwen series. Compared with conventional instruction-tuned models, QwQ, which is capable of thinking and reasoning, can achieve significantly enhanced performance in downstream tasks, especially hard problems. QwQ-32B is the medium-sized reasoning model, which is capable of achieving competitive performance against state-of-the-art reasoning models, e.g., DeepSeek-R1, o1-mini.",
    display_name = "Qwen: QwQ 32B",
    id = "qwen/qwq-32b",
    input_token_price_per_m = 1800,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 2000,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "qwen/qwq-32b"
  },
  {
    context_size = 16384,
    created = 1721801867,
    description = "Meta's latest class of models, Llama 3.1, launched with a variety of sizes and configurations. The 8B instruct-tuned version is particularly fast and efficient. It has demonstrated strong performance in human evaluations, outperforming several leading closed-source models.",
    display_name = "Llama 3.1 8B Instruct",
    id = "meta-llama/llama-3.1-8b-instruct",
    input_token_price_per_m = 500,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 500,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {
      "NEW"
    },
    title = "meta-llama/llama-3.1-8b-instruct"
  },
  {
    context_size = 64000,
    created = 1737876558,
    description = "DeepSeek R1 is the latest open-source model released by the DeepSeek team, featuring impressive reasoning capabilities, particularly achieving performance comparable to OpenAI's o1 model in mathematics, coding, and reasoning tasks.",
    display_name = "DeepSeek R1",
    id = "deepseek/deepseek-r1",
    input_token_price_per_m = 40000,
    max_output_tokens = 8196,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 40000,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "deepseek/deepseek-r1"
  },
  {
    context_size = 64000,
    created = 1736942072,
    description = "DeepSeek-V3 is the latest model from the DeepSeek team, building upon the instruction following and coding abilities of the previous versions. Pre-trained on nearly 15 trillion tokens, the reported evaluations reveal that the model outperforms other open-source models and rivals leading closed-source models.",
    display_name = "DeepSeek V3",
    id = "deepseek/deepseek_v3",
    input_token_price_per_m = 8900,
    max_output_tokens = 8000,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 8900,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {
      "NEW"
    },
    title = "deepseek/deepseek_v3"
  },
  {
    context_size = 32768,
    created = 1721801064,
    description = "Meta's latest class of models, Llama 3.1, has launched with a variety of sizes and configurations. The 70B instruct-tuned version is optimized for high-quality dialogue use cases. It has demonstrated strong performance in human evaluations compared to leading closed-source models.",
    display_name = "Llama 3.1 70B Instruct",
    id = "meta-llama/llama-3.1-70b-instruct",
    input_token_price_per_m = 3400,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 3900,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {
      "NEW"
    },
    title = "meta-llama/llama-3.1-70b-instruct"
  },
  {
    context_size = 131072,
    created = 1733560109,
    description = "The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out). The Llama 3.3 instruction tuned text only model is optimized for multilingual dialogue use cases and outperforms many of the available open source and closed chat models on common industry benchmarks.\n\nSupported languages: English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai.",
    display_name = "Llama 3.3 70B Instruct",
    id = "meta-llama/llama-3.3-70b-instruct",
    input_token_price_per_m = 3900,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 3900,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {
      "NEW"
    },
    title = "meta-llama/llama-3.3-70b-instruct"
  },
  {
    context_size = 131072,
    created = 1722337858,
    description = "A 12B parameter model with a 128k token context length built by Mistral in collaboration with NVIDIA. The model is multilingual, supporting English, French, German, Spanish, Italian, Portuguese, Chinese, Japanese, Korean, Arabic, and Hindi. It supports function calling and is released under the Apache 2.0 license.",
    display_name = "Mistral Nemo",
    id = "mistralai/mistral-nemo",
    input_token_price_per_m = 1700,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 1700,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "mistralai/mistral-nemo"
  },
  {
    context_size = 64000,
    created = 1738498371,
    description = "DeepSeek R1 Distill Qwen 14B is a distilled large language model based on Qwen 2.5 14B, using outputs from DeepSeek R1. It outperforms OpenAI's o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.\n\nOther benchmark results include:\n\nAIME 2024 pass@1: 69.7\nMATH-500 pass@1: 93.9\nCodeForces Rating: 1481\nThe model leverages fine-tuning from DeepSeek R1's outputs, enabling competitive performance comparable to larger frontier models.",
    display_name = "DeepSeek: DeepSeek R1 Distill Qwen 14B",
    id = "deepseek/deepseek-r1-distill-qwen-14b",
    input_token_price_per_m = 1500,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 1500,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {
      "NEW"
    },
    title = "deepseek/deepseek-r1-distill-qwen-14b"
  },
  {
    context_size = 64000,
    created = 1738498293,
    description = "DeepSeek R1 Distill Qwen 32B is a distilled large language model based on Qwen 2.5 32B, using outputs from DeepSeek R1. It outperforms OpenAI's o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.\n\nOther benchmark results include:\nAIME 2024 pass@1: 72.6\nMATH-500 pass@1: 94.3\nCodeForces Rating: 1691\nThe model leverages fine-tuning from DeepSeek R1's outputs, enabling competitive performance comparable to larger frontier models.",
    display_name = "DeepSeek: DeepSeek R1 Distill Qwen 32B",
    id = "deepseek/deepseek-r1-distill-qwen-32b",
    input_token_price_per_m = 3000,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 3000,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {
      "NEW"
    },
    title = "deepseek/deepseek-r1-distill-qwen-32b"
  },
  {
    context_size = 32000,
    created = 1737957190,
    description = "DeepSeek R1 Distill LLama 70B",
    display_name = "DeepSeek R1 Distill LLama 70B",
    id = "deepseek/deepseek-r1-distill-llama-70b",
    input_token_price_per_m = 8000,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 8000,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "deepseek/deepseek-r1-distill-llama-70b"
  },
  {
    context_size = 8192,
    created = 1732875917,
    description = "Sao10K/L3-8B-Stheno-v3.2 is a highly skilled actor that excels at fully immersing itself in any role assigned.",
    display_name = "L3 8B Stheno V3.2",
    id = "Sao10K/L3-8B-Stheno-v3.2",
    input_token_price_per_m = 500,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 500,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {
      "NEW"
    },
    title = "Sao10K/L3-8B-Stheno-v3.2"
  },
  {
    context_size = 4096,
    created = 1714024873,
    description = "The idea behind this merge is that each layer is composed of several tensors, which are in turn responsible for specific functions. Using MythoLogic-L2's robust understanding as its input and Huginn's extensive writing capability as its output seems to have resulted in a model that exceeds at both, confirming my theory. (More details to be released at a later time).",
    display_name = "Mythomax L2 13B",
    id = "gryphe/mythomax-l2-13b",
    input_token_price_per_m = 900,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 900,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {
      "HOT"
    },
    title = "gryphe/mythomax-l2-13b"
  },
  {
    context_size = 32000,
    created = 1738498617,
    description = "DeepSeek R1 Distill Llama 8B is a distilled large language model based on Llama-3.1-8B-Instruct, using outputs from DeepSeek R1. ",
    display_name = "DeepSeek: DeepSeek R1 Distill Llama 8B",
    id = "deepseek/deepseek-r1-distill-llama-8b",
    input_token_price_per_m = 400,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 400,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {
      "NEW"
    },
    title = "deepseek/deepseek-r1-distill-llama-8b"
  },
  {
    context_size = 32000,
    created = 1728962258,
    description = "Qwen2.5 is the latest series of Qwen large language models. For Qwen2.5, we release a number of base language models and instruction-tuned language models ranging from 0.5 to 72 billion parameters.",
    display_name = "Qwen 2.5 72B Instruct",
    id = "qwen/qwen-2.5-72b-instruct",
    input_token_price_per_m = 3800,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 4000,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "qwen/qwen-2.5-72b-instruct"
  },
  {
    context_size = 8192,
    created = 1714024874,
    description = "Meta's latest class of model (Llama 3) launched with a variety of sizes & flavors. This 8B instruct-tuned version was optimized for high quality dialogue usecases. It has demonstrated strong performance compared to leading closed-source models in human evaluations.",
    display_name = "Llama 3 8B Instruct",
    id = "meta-llama/llama-3-8b-instruct",
    input_token_price_per_m = 400,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 400,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "meta-llama/llama-3-8b-instruct"
  },
  {
    context_size = 65535,
    created = 1713938472,
    description = "WizardLM-2 8x22B is Microsoft AI's most advanced Wizard model. It demonstrates highly competitive performance compared to leading proprietary models, and it consistently outperforms all existing state-of-the-art opensource models.",
    display_name = "Wizardlm 2 8x22B",
    id = "microsoft/wizardlm-2-8x22b",
    input_token_price_per_m = 6200,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 6200,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {
      "HOT"
    },
    title = "microsoft/wizardlm-2-8x22b"
  },
  {
    context_size = 8192,
    created = 1721311424,
    description = "Gemma 2 9B by Google is an advanced, open-source language model that sets a new standard for efficiency and performance in its size class.\nDesigned for a wide variety of tasks, it empowers developers and researchers to build innovative applications, while maintaining accessibility, safety, and cost-effectiveness.",
    display_name = "Gemma 2 9B",
    id = "google/gemma-2-9b-it",
    input_token_price_per_m = 800,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 800,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "google/gemma-2-9b-it"
  },
  {
    context_size = 32768,
    created = 1719492913,
    description = "A high-performing, industry-standard 7.3B parameter model, with optimizations for speed and context length.",
    display_name = "Mistral 7B Instruct",
    id = "mistralai/mistral-7b-instruct",
    input_token_price_per_m = 590,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 590,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "mistralai/mistral-7b-instruct"
  },
  {
    context_size = 8192,
    created = 1714024815,
    description = "Meta's latest class of model (Llama 3) launched with a variety of sizes & flavors. This 70B instruct-tuned version was optimized for high quality dialogue usecases. It has demonstrated strong performance compared to leading closed-source models in human evaluations.",
    display_name = "Llama3 70b Instruct",
    id = "meta-llama/llama-3-70b-instruct",
    input_token_price_per_m = 5100,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 7400,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {
      "HOT"
    },
    title = "meta-llama/llama-3-70b-instruct"
  },
  {
    context_size = 4096,
    created = 1721992172,
    description = 'OpenChat 7B is a library of open-source language models, fine-tuned with "C-RLFT (Conditioned Reinforcement Learning Fine-Tuning)" - a strategy inspired by offline reinforcement learning. It has been trained on mixed-quality data without preference labels.',
    display_name = "OpenChat 7B",
    id = "openchat/openchat-7b",
    input_token_price_per_m = 600,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 600,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "openchat/openchat-7b"
  },
  {
    context_size = 8192,
    created = 1719493012,
    description = "Hermes 2 Pro is an upgraded, retrained version of Nous Hermes 2, consisting of an updated and cleaned version of the OpenHermes 2.5 Dataset, as well as a newly introduced Function Calling and JSON Mode dataset developed in-house.",
    display_name = "Hermes 2 Pro Llama 3 8B",
    id = "nousresearch/hermes-2-pro-llama-3-8b",
    input_token_price_per_m = 1400,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 1400,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "nousresearch/hermes-2-pro-llama-3-8b"
  },
  {
    context_size = 8192,
    created = 1718699128,
    description = "The uncensored llama3 model is a powerhouse of creativity, excelling in both roleplay and story writing. It offers a liberating experience during roleplays, free from any restrictions. This model stands out for its immense creativity, boasting a vast array of unique ideas and plots, truly a treasure trove for those seeking originality. Its unrestricted nature during roleplays allows for the full breadth of imagination to unfold, akin to an enhanced, big-brained version of Stheno. Perfect for creative minds seeking a boundless platform for their imaginative expressions, the uncensored llama3 model is an ideal choice",
    display_name = "L3 70B Euryale V2.1\t",
    id = "sao10k/l3-70b-euryale-v2.1",
    input_token_price_per_m = 14800,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 14800,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "sao10k/l3-70b-euryale-v2.1"
  },
  {
    context_size = 16000,
    created = 1719492271,
    description = "Dolphin 2.9 is designed for instruction following, conversational, and coding. This model is a finetune of Mixtral 8x22B Instruct. It features a 64k context length and was fine-tuned with a 16k sequence length using ChatML templates.The model is uncensored and is stripped of alignment and bias. It requires an external alignment layer for ethical use.",
    display_name = "Dolphin Mixtral 8x22B",
    id = "cognitivecomputations/dolphin-mixtral-8x22b",
    input_token_price_per_m = 9000,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 9000,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "cognitivecomputations/dolphin-mixtral-8x22b"
  },
  {
    context_size = 4096,
    created = 1721215677,
    description = "This is a fine-tuned Llama-2 model designed to support longer and more detailed writing prompts, as well as next-chapter generation. It also includes an experimental role-playing instruction set with multi-round dialogues, character interactions, and varying numbers of participants",
    display_name = "Airoboros L2 70B",
    id = "jondurbin/airoboros-l2-70b",
    input_token_price_per_m = 5000,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 5000,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "jondurbin/airoboros-l2-70b"
  },
  {
    context_size = 4096,
    created = 1714024873,
    description = "Nous-Hermes-Llama2-13b is a state-of-the-art language model fine-tuned on over 300,000 instructions. This model was fine-tuned by Nous Research, with Teknium and Emozilla leading the fine tuning process and dataset curation, Redmond AI sponsoring the compute, and several other contributors.",
    display_name = "Nous Hermes Llama2 13B",
    id = "nousresearch/nous-hermes-llama2-13b",
    input_token_price_per_m = 1700,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 1700,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "nousresearch/nous-hermes-llama2-13b"
  },
  {
    context_size = 4096,
    created = 1713938473,
    description = "OpenHermes 2.5 Mistral 7B is a state of the art Mistral Fine-tune, a continuation of OpenHermes 2 model, which trained on additional code datasets.",
    display_name = "Openhermes2.5 Mistral 7B",
    id = "teknium/openhermes-2.5-mistral-7b",
    input_token_price_per_m = 1700,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 1700,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "teknium/openhermes-2.5-mistral-7b"
  },
  {
    context_size = 4096,
    created = 1718626452,
    description = "A merge with a complex family tree, this model was crafted for roleplaying and storytelling. Midnight Rose is a successor to Rogue Rose and Aurora Nights and improves upon them both. It wants to produce lengthy output by default and is the best creative writing merge produced so far by sophosympatheia.",
    display_name = "Midnight Rose 70B",
    id = "sophosympatheia/midnight-rose-70b",
    input_token_price_per_m = 8000,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 8000,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "sophosympatheia/midnight-rose-70b"
  },
  {
    context_size = 8192,
    created = 1732791714,
    description = "A generalist / roleplaying model merge based on Llama 3.",
    display_name = "Sao10k L3 8B Lunaris\t",
    id = "sao10k/l3-8b-lunaris",
    input_token_price_per_m = 500,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 500,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {
      "NEW"
    },
    title = "sao10k/l3-8b-lunaris"
  },
  {
    context_size = 32768,
    created = 1734600120,
    description = "Qwen2 VL 72B is a multimodal LLM from the Qwen Team with the following key enhancements:\n\nSoTA understanding of images of various resolution & ratio: Qwen2-VL achieves state-of-the-art performance on visual understanding benchmarks, including MathVista, DocVQA, RealWorldQA, MTVQA, etc.\n\nUnderstanding videos of 20min+: Qwen2-VL can understand videos over 20 minutes for high-quality video-based question answering, dialog, content creation, etc.\n\nAgent that can operate your mobiles, robots, etc.: with the abilities of complex reasoning and decision making, Qwen2-VL can be integrated with devices like mobile phones, robots, etc., for automatic operation based on visual environment and text instructions.\n\nMultilingual Support: to serve global users, besides English and Chinese, Qwen2-VL now supports the understanding of texts in different languages inside images, including most European languages, Japanese, Korean, Arabic, Vietnamese, etc.",
    display_name = "Qwen 2 VL 72B Instruct",
    id = "qwen/qwen-2-vl-72b-instruct",
    input_token_price_per_m = 4500,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 4500,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {
      "NEW"
    },
    title = "qwen/qwen-2-vl-72b-instruct"
  },
  {
    context_size = 131000,
    created = 1732609540,
    description = "The Meta Llama 3.2 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction-tuned generative models in 1B and 3B sizes (text in/text out).",
    display_name = "Llama 3.2 1B Instruct\t",
    id = "meta-llama/llama-3.2-1b-instruct",
    input_token_price_per_m = 200,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 200,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "meta-llama/llama-3.2-1b-instruct"
  },
  {
    context_size = 32768,
    created = 1732609420,
    description = "Llama 3.2 11B Vision is a multimodal model with 11 billion parameters, designed to handle tasks combining visual and textual data. It excels in tasks such as image captioning and visual question answering, bridging the gap between language generation and visual reasoning. Pre-trained on a massive dataset of image-text pairs, it performs well in complex, high-accuracy image analysis. Its ability to integrate visual understanding with language processing makes it an ideal solution for industries requiring comprehensive visual-linguistic AI applications, such as content creation, AI-driven customer service, and research.",
    display_name = "Llama 3.2 11B Vision Instruct\t",
    id = "meta-llama/llama-3.2-11b-vision-instruct",
    input_token_price_per_m = 600,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 600,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "meta-llama/llama-3.2-11b-vision-instruct"
  },
  {
    context_size = 32768,
    created = 1732607748,
    description = "The Meta Llama 3.2 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction-tuned generative models in 1B and 3B sizes (text in/text out)",
    display_name = "Llama 3.2 3B Instruct",
    id = "meta-llama/llama-3.2-3b-instruct",
    input_token_price_per_m = 300,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 500,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "meta-llama/llama-3.2-3b-instruct"
  },
  {
    context_size = 8192,
    created = 1729501055,
    description = "Meta's latest class of models, Llama 3.1, launched with a variety of sizes and configurations. The 8B instruct-tuned version is particularly fast and efficient. It has demonstrated strong performance in human evaluations, \n                   outperforming several leading closed-source models.",
    display_name = "Llama 3.1 8B Instruct BF16",
    id = "meta-llama/llama-3.1-8b-instruct-bf16",
    input_token_price_per_m = 600,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 600,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "meta-llama/llama-3.1-8b-instruct-bf16"
  },
  {
    context_size = 8192,
    created = 1726742141,
    description = "Euryale L3.1 70B v2.2 is a model focused on creative roleplay from Sao10k. It is the successor of Euryale L3 70B v2.1.",
    display_name = "L31 70B Euryale V2.2",
    id = "sao10k/l31-70b-euryale-v2.2",
    input_token_price_per_m = 14800,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 14800,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "sao10k/l31-70b-euryale-v2.2"
  },
  {
    context_size = 32768,
    created = 1726661307,
    description = "Qwen2 is the newest series in the Qwen large language model family. Qwen2 7B is a transformer-based model that demonstrates exceptional performance in language understanding, multilingual capabilities, programming, mathematics, and reasoning.",
    display_name = "Qwen 2 7B Instruct",
    id = "qwen/qwen-2-7b-instruct",
    input_token_price_per_m = 540,
    model_type = "chat",
    object = "model",
    output_token_price_per_m = 540,
    owned_by = "unknown",
    parent = "",
    permission = vim.NIL,
    root = "",
    status = 1,
    tags = {},
    title = "qwen/qwen-2-7b-instruct"
  }
}
